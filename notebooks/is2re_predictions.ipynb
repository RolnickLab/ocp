{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    if not(changed):\n",
    "        raise Exception()\n",
    "except:\n",
    "    sys.path.append(str(Path(\".\").absolute().parent))\n",
    "    changed = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.notebooks_utils import get_activation, load_checkpoint\n",
    "\n",
    "job_id = \"4344494\" # faenet\n",
    "\n",
    "trainer = load_checkpoint(job_id)\n",
    "train_loader = trainer.get_dataloader(trainer.datasets[\"train\"], trainer.samplers[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.notebooks_utils import oc20_to_graph, plot_element_3d, process_datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocpmodels.modules.evaluator import Evaluator\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = trainer.get_dataloader(trainer.datasets[\"val_id\"], trainer.samplers[\"val_id\"])\n",
    "trainer.model.eval()\n",
    "evaluator = Evaluator(\n",
    "    task=trainer.task_name,\n",
    "    model_regresses_forces=\"\",\n",
    ")\n",
    "\n",
    "batch = next(iter(val_loader))\n",
    "maes = []\n",
    "for _ in range(1000):\n",
    "    with torch.cuda.amp.autocast(enabled=trainer.scaler is not None):\n",
    "        preds = energy_prediction = trainer.model_forward(batch, mode=\"val\")\n",
    "    metrics = trainer.compute_metrics(preds, batch, evaluator, metrics={})\n",
    "    maes.append(metrics[\"energy_mae\"][\"metric\"])\n",
    "sns.displot(maes, kde=True)\n",
    "plt.title(\"Distribution of MAE for energy prediction on the same element\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/network/scratch/s/schmidtv/ocp/datasets/ocp/per_ads/oc20_data_mapping.pkl\"\n",
    "metadata = pickle.load(open(directory, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics = trainer.validate(\"val_id\", disable_tqdm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "\n",
    "pbar = tqdm(total=len(val_loader))\n",
    "scores = defaultdict(list)\n",
    "mispredicted_elements = []\n",
    "mispredicted_indices = [] \n",
    "\n",
    "for i, batch in enumerate(val_loader):\n",
    "    with torch.cuda.amp.autocast(enabled=trainer.scaler is not None):\n",
    "        preds = energy_prediction = trainer.model_forward(batch, mode=\"val\")\n",
    "    metrics = trainer.compute_metrics(preds, batch, evaluator, metrics={})\n",
    "    mae = metrics[\"energy_mae\"][\"metric\"]\n",
    "    scores[\"mae\"].append(mae)\n",
    "    pbar.set_description(f\"MAE: {mae}\")\n",
    "    pbar.update(1)\n",
    "    pbar.refresh()\n",
    "\n",
    "    data_graph = oc20_to_graph(batch[0], processed=False)\n",
    "    try:\n",
    "        scores[\"diameter\"].append(nx.diameter(data_graph))\n",
    "    except:\n",
    "        scores[\"diameter\"].append(0)\n",
    "    scores[\"connected\"].append(nx.is_connected(data_graph))\n",
    "    scores[\"number_of_nodes\"].append(data_graph.number_of_nodes())\n",
    "    scores[\"number_of_edges\"].append(data_graph.number_of_edges())\n",
    "    scores[\"edges/nodes\"].append(data_graph.number_of_edges() / data_graph.number_of_nodes())\n",
    "    # scores[\"density\"].append(nx.density(data_graph))\n",
    "    scores[\"target\"].append(batch[0].y_relaxed.cpu().numpy()[0])\n",
    "    scores[\"n_surface\"].append((batch[0].tags.cpu().numpy() == 1).sum())\n",
    "    scores[\"n_adsorbate\"].append((batch[0].tags.cpu().numpy() == 2).sum())\n",
    "    scores[\"y_init\"].append(batch[0].y_init.cpu().numpy()[0])\n",
    "    scores[\"average_degree\"].append(np.mean(list(dict(data_graph.degree()).values())))\n",
    "    scores[\"ads_symbols\"].append(metadata[f\"random{batch[0].sid.cpu().numpy()[0]}\"][\"ads_symbols\"])\n",
    "    scores[\"ads_id\"].append(metadata[f\"random{batch[0].sid.cpu().numpy()[0]}\"][\"ads_id\"])\n",
    "    scores[\"anomaly\"].append(metadata[f\"random{batch[0].sid.cpu().numpy()[0]}\"][\"anomaly\"])\n",
    "    scores[\"bulk_symbols\"].append(metadata[f\"random{batch[0].sid.cpu().numpy()[0]}\"][\"bulk_symbols\"])\n",
    "    scores[\"bulk_id\"].append(metadata[f\"random{batch[0].sid.cpu().numpy()[0]}\"][\"bulk_id\"])\n",
    "    scores[\"shift\"].append(metadata[f\"random{batch[0].sid.cpu().numpy()[0]}\"][\"shift\"])\n",
    "\n",
    "\n",
    "    if mae > 10:\n",
    "        mispredicted_elements.append(batch[0])\n",
    "        mispredicted_indices.append(i)\n",
    "\n",
    "\n",
    "pbar.close()\n",
    "sns.displot(scores[\"mae\"], kde=True)\n",
    "plt.title(\"Distribution of MAE for energy prediction on different elements\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7\n",
    "\n",
    "fig, axes = plt.subplots(n, 3, figsize=(10, 20))\n",
    "\n",
    "scores[\"edges + nodes\"] = np.array(scores[\"number_of_edges\"]) + np.array(scores[\"number_of_nodes\"])\n",
    "scores['y_init - target'] = np.array(scores[\"y_init\"]) - np.array(scores[\"target\"])\n",
    "scores[\"abs_target\"] = np.abs(np.array(scores[\"target\"]))\n",
    "scores[\"connected\"] = np.array(scores[\"connected\"]).astype(int)\n",
    "\n",
    "for i, key in enumerate(scores.keys()):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    if key not in [] and \"symbol\" not in key:\n",
    "        ax.hist(scores[key])\n",
    "    ax.set_title(key)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(n, 3, figsize=(10, 20))\n",
    "\n",
    "for i, key in enumerate(scores.keys()):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    if key not in [] and \"symbol\" not in key:\n",
    "        ax.plot(scores[key], scores[\"mae\"], \"o\")\n",
    "        ax.set_title(f\"{key} - Pearson: {np.corrcoef(scores[key], scores['mae'])[0, 1]:.2f}\")\n",
    "    ax.set_ylabel(\"MAE\")\n",
    "    ax.set_xlabel(key)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "threshold = 0\n",
    "linreg = Ridge(alpha=1e-3)\n",
    "X_list = []\n",
    "keys = []\n",
    "for key in scores.keys():\n",
    "    if key not in [\"mae\"] and \"symbols\" not in key:\n",
    "    # if key not in [\"mae\", \"y_init\", \"target\", \"y_init - target\"] and \"symbol\" not in key:\n",
    "        X_list.append(scores[key][scores[\"mae\"] > threshold].astype(float))\n",
    "        keys.append(key)\n",
    "\n",
    "X = np.stack(X_list, axis=1)\n",
    "y = scores[\"mae\"][scores[\"mae\"] > threshold]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "y_pred_tree = xgb_reg.predict(X_test)\n",
    "mae_tree = mean_absolute_error(y_test, y_pred_tree)\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "print(f\"Linear regression: MAE: {mae:.2f}, MSE: {mse:.2f}\")\n",
    "\n",
    "plt.plot(y_test, y_pred, \"o\")\n",
    "plt.xlabel(\"True MAE\")\n",
    "plt.ylabel(\"Predicted MAE\")\n",
    "plt.title(f\"MAE: {mae:.2f}, MSE: {mse:.2f}\")\n",
    "plt.show()\n",
    "\n",
    "plt.barh(keys, linreg.coef_)\n",
    "plt.xlabel(\"Coefficient\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Linear regression coefficients\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(y_test, y_pred_tree, \"o\")\n",
    "plt.xlabel(\"True MAE\")\n",
    "plt.ylabel(\"Predicted MAE\")\n",
    "plt.title(f\"MAE: {mae_tree:.2f}, MSE: {mse_tree:.2f}\")\n",
    "plt.show()\n",
    "\n",
    "plt.barh(keys, xgb_reg.feature_importances_)\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"XGBoost feature importances\")\n",
    "plt.show()\n",
    "print(list(zip(xgb_reg.feature_importances_, keys)))\n",
    "\n",
    "print(list(zip(linreg.coef_, keys)), linreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot of mae on different bulk_id\n",
    "\n",
    "keys = [\"bulk_id\", \"ads_id\"]\n",
    "symbols_keys = [\"bulk_symbols\", \"ads_symbols\"]\n",
    "\n",
    "for key, symbols_key in zip(keys, symbols_keys):\n",
    "    n_bulks = min(80, len(np.unique(scores[key])))\n",
    "    bulk_ids = np.array(scores[key])\n",
    "    bulk_symbols = np.array(scores[symbols_key])\n",
    "    unique_bulk_ids = np.unique(bulk_ids)[:n_bulks]\n",
    "    bulk_ids_index = np.zeros_like(bulk_ids).astype(bool)\n",
    "    bulk_symbols_plot = np.zeros(n_bulks).astype(str)\n",
    "    for i, bulk_id in enumerate(unique_bulk_ids):\n",
    "        bulk_ids_index[bulk_ids == bulk_id] = True\n",
    "        bulk_symbols_plot[i] = bulk_symbols[bulk_ids == bulk_id][0]\n",
    "    bulk_ids_plot = np.array(bulk_ids)[bulk_ids_index]\n",
    "    maes = np.array(scores[\"mae\"])[bulk_ids_index]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 5))\n",
    "    ax.boxplot([maes[bulk_ids_plot == bulk_id] for bulk_id in unique_bulk_ids])\n",
    "    ax.set_xticklabels(bulk_symbols_plot)\n",
    "    ax.set_title(f\"MAE distribution for different {key}\")\n",
    "    ax.set_xlabel(key)\n",
    "    ax.set_ylabel(\"MAE\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
