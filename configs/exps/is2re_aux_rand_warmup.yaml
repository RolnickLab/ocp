# Same as compFA with x2 batch size, usual (highest) init lr, comparing warmup steps up to half of max_steps
job:
  mem: 80GB
  cpus: 4
  gres: gpu:1
  partition: long
  # time: 15:00:00

default:
  mode: train
  optim:
    batch_size: 256
    eval_batch_size: 256
    optimizer: AdamW
    auxiliary_decay: True
    auxiliary_task_weight: 15
    energy_coefficient: 1.0
    max_epochs: 50
    scheduler: LinearWarmupCosineAnnealingLR
    lr_initial: 0.002 #usual lr of top configs
    warmup_factor: 0.2
  cp_data_to_tmpdir: True
  normalizer: null
  model:
    otf_graph: False
    max_num_neighbors: 40
    noisy_nodes: True
    num_interactions: 10
  trainer: single
  logger: wandb
  early_stop: False
  test_ri: True

  frame_averaging: 2D
  fa_method: se3-random

  dataset:
    train:
      noisy_nodes:
        type: rand #rand or rand_deter or constant
        interpolate_threshold: 0.5
        min_interpolate_factor: 0.0
        gaussian_noise_std: 0.3

  task:
    dataset: lmdb_noisy #single_point_lmdb  
    description: "Relaxed state energy prediction from initial structure."
    type: regression
    metric: mae
    labels:
      - relaxed energy

# ------------------------usual 6000 warmup steps------------------------
runs:
  - config: faenet-is2re_aux-all
    note: "usual 6000 warmup steps"
    optim:
      warmup_steps: 6000

  - config: faenet-is2re_aux-all
    note: "12000 warmup steps"
    optim:
      warmup_steps: 12000
  
  - config: faenet-is2re_aux-all
    note: "24000 warmup steps"
    optim:
      warmup_steps: 24000

  - config: faenet-is2re_aux-all
    note: "48000 warmup steps"
    optim:
      warmup_steps: 48000

  - config: faenet-is2re_aux-all
    note: "96000 warmup steps"
    optim:
      warmup_steps: 96000
